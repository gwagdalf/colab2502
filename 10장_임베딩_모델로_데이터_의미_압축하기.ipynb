{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OOnfiHP5etpX"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwagdalf/colab2502/blob/main/10%E1%84%8C%E1%85%A1%E1%86%BC_%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%87%E1%85%A6%E1%84%83%E1%85%B5%E1%86%BC_%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%E1%84%85%E1%85%A9_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5_%E1%84%8B%E1%85%B4%E1%84%86%E1%85%B5_%E1%84%8B%E1%85%A1%E1%86%B8%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 준비"
      ],
      "metadata": {
        "id": "2ne1OUpIaRzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드를 실행해 현재 사용 중인 Python 버전이 3.11.11인지 확인해 주세요."
      ],
      "metadata": {
        "id": "RgAECe8-a8CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "# 실행 결과\n",
        "# 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]"
      ],
      "metadata": {
        "id": "0JhNeuU2ZZ2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971f3a24-dac2-4b7d-e481-f7dcfac43dd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드를 실행해 실습에 필요한 라이브러리들을 설치해 주세요(약 2분 소요).\n",
        "\n",
        "설치 후 런타임 도구를 재 시작해야 합니다(설치 완료 시 아래와 같은 안내창 나타남).\n",
        "\n",
        "```\n",
        "세션 다시 시작\n",
        "\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "  [nvidia]\n",
        "You must restart the runtime in order to use newly installed versions.\n",
        "Restarting will lose all runtime state, including local variables.\n",
        "```"
      ],
      "metadata": {
        "id": "1YoMYD64aXPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets faiss-cpu llama-index llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EQ6LhbNobeQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2c82d5-f04d-4565-f303-633766eaf958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.25-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl.metadata (767 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.25 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.25-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (3.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.61.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.15-py3-none-any.whl.metadata (902 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.48.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.12.25-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl (8.9 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.25-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl (16 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.15-py3-none-any.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.5/264.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/24.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.1 텍스트 임베딩 이해하기\n",
        "컴퓨터는 숫자 형식의 데이터만 연산할 수 있기 때문에 텍스트, 이미지, 음성 등을 컴퓨터로 처리하기 위해서는 데이터를 숫자 형식으로 변환해야 합니다.\n",
        "\n",
        "이때, 데이터를 숫자로 변환하는 과정 또는 결과 벡터를 <u>임베딩(embedding)</u>이라고 합니다.\n",
        "<br/>\n",
        "<br/>\n",
        "Huggingface에서는 언어 모델을 관리하는 transformers 라이브러리와 문장 임베딩을 담당하는 sentence-transformers 라이브러리를 제공합니다.\n",
        "\n",
        "이번 장에서는 sentence-transformers 라이브러리를 이용해 문장 임베딩을 실습해 보겠습니다."
      ],
      "metadata": {
        "id": "-mZa9-eadQF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.1. 문장 임베딩 방식의 장점\n",
        "데이터를 숫자로 표현함으로써 데이터가 서로 유사한지, 관련이 있는지 등의 중요한 정보를 확인할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "iG-EK80-d4Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 10.1 코드를 실행해 각 단어의 임베딩 결과와 단어 간 유사도를 확인해 보세요.\n",
        "\n",
        "연관성이 높아 보이는 단어의 조합에서 점수가 높게 책정된 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "RiPPCo0m0DFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.1: 문장 임베딩을 활용한 단어 간 유사도 계산\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "smodel = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
        "dens_embeddings = smodel.encode([\"빨강색\", \"사과\", \"비행기\", \"과일\", \"자동차\", \"공항\", \"오렌지\"])\n",
        "\n",
        "print(cosine_similarity(dens_embeddings))\n",
        "\n",
        "# 실행 결과\n",
        "# [[1.0000002  0.14998594 0.09523749 0.24652015 0.13664223 0.09888056\n",
        "#   0.42369962]\n",
        "#  [0.14998594 1.0000001  0.14241984 0.20996779 0.19464257 0.16678154\n",
        "#   0.2447487 ]\n",
        "#  [0.09523749 0.14241984 1.         0.06879357 0.42621619 0.597421\n",
        "#   0.04521934]\n",
        "#  [0.24652015 0.20996779 0.06879357 1.0000004  0.24353838 0.15006337\n",
        "#   0.51431495]\n",
        "#  [0.13664223 0.19464257 0.42621619 0.24353838 1.0000002  0.23871656\n",
        "#   0.03931421]\n",
        "#  [0.09888056 0.16678154 0.597421   0.15006337 0.23871656 0.9999999\n",
        "#   0.12107833]\n",
        "#  [0.42369962 0.2447487  0.04521934 0.51431495 0.03931421 0.12107833\n",
        "#   0.9999999 ]]"
      ],
      "metadata": {
        "id": "12P2Qi71dXDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.2. 원핫 인코딩\n",
        "원핫 인코딩 방식은 데이터를 카테고리 별로 분류할 때는 적합하나, 데이터 사이의 관계를 표현할 수 없다는 단점이 있습니다."
      ],
      "metadata": {
        "id": "OOnfiHP5etpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 10.2 코드를 실행해 원핫 인코딩 한 단어 사이의 유사도를 확인해 보세요.\n",
        "\n",
        "유사성이 높은 단어끼리 코사인 유사도를 측정했음에도 0이 나오는 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "QFY_ppCne0XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.2: 원핫 인코딩의 한계\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "word_dict = {\n",
        "    \"빨강색\": np.array([[1, 0, 0, 0, 0, 0, 0]]),\n",
        "    \"사과\": np.array([[0, 1, 0, 0, 0, 0, 0]]),\n",
        "    \"비행기\": np.array([[0, 0, 1, 0, 0, 0, 0]]),\n",
        "    \"과일\": np.array([[0, 0, 0, 1, 0, 0, 0]]),\n",
        "    \"자동차\": np.array([[0, 0, 0, 0, 1, 0, 0]]),\n",
        "    \"공항\": np.array([[0, 0, 0, 0, 0, 1, 0]]),\n",
        "    \"오렌지\": np.array([[0, 0, 0, 0, 0, 0, 1]]),\n",
        "}\n",
        "\n",
        "print(cosine_similarity(word_dict[\"빨강색\"], word_dict[\"사과\"]))\n",
        "print(cosine_similarity(word_dict[\"과일\"], word_dict[\"오렌지\"]))\n",
        "\n",
        "# 실행 결과\n",
        "# [[0.]]\n",
        "# [[0.]]"
      ],
      "metadata": {
        "id": "8RGs318mez8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.3 백오브워즈\n",
        "<u>백오브워즈(Bag of Words)</u>는 '비슷한 단어가 많이 나오면 비슷한 문장 또는 문서라는 가정'을 활용해 문서를 숫자로 변환하는 방식입니다.\n",
        "\n",
        "단어의 순서에 관계없이 해당 문서에 등장한 단어와 그 등장 횟수를 집계합니다.\n",
        "\n",
        "||대출|증시|AI|부동산|LLM|구글\n",
        "|---|---|---|---|---|---|---|\n",
        "|경제 기사 1|3|3|-|2|-|-|\n",
        "|경제 기사 2|-|5|3|-|-|-|\n",
        "|IT 기사 1|-|-|3|-|4|2|\n",
        "|IT 기사 2|-|-|2|1|2|-|\n",
        "\n",
        "위 표에서는 4개의 기사에서 등장한 단어의 출현 빈도를 정리했습니다.\n",
        "\n",
        "백오브워즈 방식에서 '대출', '증시', '부동산'과 같은 단어가 자주 사용된다면 경제 기사일 가능성이 높다고 판단합니다.\n",
        "\n",
        "IT 기사에서는 해당 단어가 사용되지 않거나 상대적으로 훨씬 적게 나타날 것입니다.\n",
        "<br/>\n",
        "<br/>\n",
        "다만, 단어의 출현 빈도로만 문서의 의미를 파악하는 것은 한계가 있습니다.\n",
        "\n",
        "'AI'라는 단어가 높은 빈도로 나왔다고 해도 경제 관련 기사일 수도 있기 때문입니다(e.g. AI 관련 경제 뉴스).\n"
      ],
      "metadata": {
        "id": "sY17L9NI0b3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.4 TF-IDF\n",
        "<u>TF-IDF(Term Frequency-Inverse Document Frequency)</u>는 많은 문서에서 등장하는 단어의 중요도를 작게 만드는 방식입니다.\n",
        "공식은 다음과 같습니다.\n",
        "\n",
        "> TF-IDF(w) = TF(w) x log(N / DF(w))\n",
        ">\n",
        "> * TF(w): 특정 문서에서 특정 단어 w가 등장한 횟수\n",
        "> * DF(w): 특정 단어 w가 등장한 문서의 수\n",
        "\n",
        "아래의 표를 예시로 사용하겠습니다.\n",
        "\n",
        "||TF(\"이\")|TF(\"LLM\")|DF(\"이\")|DF(\"LLM\")|TF-IDF(\"이\")|TF-IDF(\"LLM\")|\n",
        "|---|---|---|---|---|---|---|\n",
        "|경제 기사 1|10|0|4|2|0|0|\n",
        "|경제 기사 2|8|0|4|2|0|0|\n",
        "|IT 기사 1|5|4|4|2|0|4 x log(4 / 2)|\n",
        "|IT 기사 2|9|2|4|2|0|2 x log(4 / 2)|\n",
        "\n",
        "조사 '이'는 단어 'LLM'에 비해 IT 기사에서 더 많이 등장하지만, 모든 문서에서 사용하기 때문에 중요도가 없다고 판단합니다(log(4 / 4) = 0).\n",
        "\n",
        "단어 'LLM'은 2개 기사에서만 등장하기 때문에 log의 값이 0이 아니게 되어 최종적으로 유사한 기사(문서)를 찾아낼 수 있습니다.\n",
        "<br/>\n",
        "<br/>\n",
        "하지만 여전히 한계가 존재합니다.\n",
        "\n",
        "만약, 총 10,000개의 단어가 전체 문서에서 사용됐다면 하나의 문장과 문서를 표현하기 위해 10,000차원의 벡터를 사용하게 되어 자원을 낭비하게 됩니다.\n",
        "\n",
        "또한, 필연적으로 벡터의 대부분의 요소가 0이 되는데, 이렇게 대부분의 요소가 0인 벡터를 희소sparse하다고 말합니다.\n",
        "\n",
        "희소한 벡터는 의미를 압축해서 담고 있지 못하기 때문에 벡터와 벡터 사이의 관계를 활용하기 어렵습니다."
      ],
      "metadata": {
        "id": "4FDlV1ZT2LT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.5 워드투벡\n",
        "<u>워드투벡(word2vec)</u>은 단어가 함께 등장하는 빈도 정보를 활용해 단어의 의미를 압축하는 임베딩 방법입니다.\n",
        "\n",
        "예를 들어, 'AI'는 'ML' 또는 '머신러닝'과, '한강'은 '라면'이나 '자전거'와 함께 등장합니다.\n",
        "\n",
        "워드투벡 방식은 두 가지 방법으로 학습합니다.\n",
        "\n",
        "(그림 10.1 첨부)\n",
        "\n",
        "\n",
        "CBOW(Continuous Bag of Words)는 주변의 단어 정보로 중간에 있을 단어를 예측하는 방식입니다.\n",
        "\n",
        "스킵그램(skip-gram)은 반대로, 가운데 단어 정보로 주변의 단어를 예측하는 방식입니다."
      ],
      "metadata": {
        "id": "o5becRh35yOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.2 문장 임베딩 방식\n",
        "워드투벡 방식으로 단어를 임베딩 벡터로 변환함으로써 단어와 단어 사이의 관계를 판단할 수 있게 되었습니다.\n",
        "\n",
        "하지만 동음이의어를 분류할 수 없다는 한계점도 있습니다.\n",
        "<br/>\n",
        "<br/>\n",
        "동음이의어를 처리해야 할 뿐만 아니라, 현실에서 텍스트를 활용할 때는 단어 보단 문장이나 문단 같은 더 큰 단위를 주로 사용합니다.\n",
        "\n",
        "따라서 여러 단어가 합쳐진 문장을 임베딩 벡터로 변환하는 방법이 필요했고, 트랜스포머 아키텍처의 개발로 위의 한계를 모두 극복할 수 있었습니다.\n",
        "\n",
        "이번 장에서는 문장 임베딩에 대해 학습하겠습니다."
      ],
      "metadata": {
        "id": "N6X3VLl_xekH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.1 문장 사이의 관계를 계산하는 두 가지 방법\n",
        "(설명 추가 필요)\n",
        "\n",
        "(그림 10.3 첨부)"
      ],
      "metadata": {
        "id": "QIRzpADkxn_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.2 바이 인코더 모델 구조\n"
      ],
      "metadata": {
        "id": "PLntBGQus-D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.3: Sentence-Transformers 라이브러리로 바이 인코더 생성하기\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "word_embedding_model = models.Transformer(\"klue/roberta-base\")\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "print(model)\n",
        "\n",
        "# 실행 결과\n",
        "# SentenceTransformer(\n",
        "#   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel\n",
        "#   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
        "# )"
      ],
      "metadata": {
        "id": "yyPFwsdotCUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.4: 평균 모드 구현 함수\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "  token_embeddings = model_output[0]\n",
        "  input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "  sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "  sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "  return sum_embeddings / sum_mask\n",
        "\n",
        "# 예제 10.5: 최대 모드 구현 함수\n",
        "def max_pooling(model_output, attention_mask):\n",
        "  token_embeddings = model_output[0]\n",
        "  input_mask_expanded = attention_mask.unsqueeze(-1),expand(token_embeddings.size()).float()\n",
        "  token_embeddings[input_mask_expanded == 0] = -1e9\n",
        "\n",
        "  return torch.max(token_embeddings, 1)[0]"
      ],
      "metadata": {
        "id": "h86uUuKPtPk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.3 Sentence-Transformers로 텍스트와 이미지 임베딩 생성해 보기"
      ],
      "metadata": {
        "id": "ig6Tlbs7tRUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 코드를 실행해 세 문장 간의 코사인 유사도를 확인해 보세요."
      ],
      "metadata": {
        "id": "gaMZ-rTDvi5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.6: 한국어 문장 임베딩 모델로 입력 문장 사이의 유사도 계산\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
        "\n",
        "embs = model.encode([\n",
        "    \"잠이 안 옵니다\",\n",
        "    \"졸음이 옵니다\",\n",
        "    \"기차가 옵니다\",\n",
        "])\n",
        "\n",
        "cos_scores = util.cos_sim(embs, embs)\n",
        "\n",
        "print(cos_scores)\n",
        "\n",
        "# 실행 결과\n",
        "# tensor([[1.0000, 0.6410, 0.1887],\n",
        "#         [0.6410, 1.0000, 0.2730],\n",
        "#         [0.1887, 0.2730, 1.0000]])"
      ],
      "metadata": {
        "id": "nNt-kv1C2tyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 코드를 실행해 이미지와 텍스트를 모두 임베딩 벡터로 변환하여 코사인 유사도를 확인해 보세요."
      ],
      "metadata": {
        "id": "fnad3WiawgGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.7: CLIP 모델을 활용한 이미지와 텍스트 임베딩 유사도 계산\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
        "img_embs = model.encode([Image.open(\"/content/drive/MyDrive/Colab Notebooks/dog.jpg\"), Image.open(\"/content/drive/MyDrive/Colab Notebooks/cat.jpg\")])\n",
        "text_embs = model.encode([\"A dog is running\", \"White cat on grass\"])\n",
        "\n",
        "cos_scores = util.cos_sim(img_embs, text_embs)\n",
        "\n",
        "print(cos_scores)\n",
        "\n",
        "# 실행 결과\n",
        "# tensor([[0.3037, 0.1270],\n",
        "#         [0.1923, 0.3030]])"
      ],
      "metadata": {
        "id": "d6aEbhDu4EwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.3 실습: 의미 검색 구현하기\n",
        "<u>의미 검색(semantic search)</u>이란 임베딩 벡터를 통해 문장이나 문서의 의미를 고려해 검색을 수행하는 것을 말합니다."
      ],
      "metadata": {
        "id": "zhwvEQ3S1839"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3.1 의미 검색 구현하기\n",
        "이번 실습에서는 KLUE의 MRC 데이터셋을 사용합니다.\n",
        "\n",
        "기사 본문과 기사 본문과 관련된 질문을 모은 데이터셋입니다.\n",
        "\n",
        "https://huggingface.co/datasets/klue/klue/viewer/mrc 에서 데이터셋을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "Scomtv5b1_6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.8 코드를 실행해 실습에 사용할 간국어 임베딩 모델과 KLUE의 MRC 데이터셋을 불러 옵니다."
      ],
      "metadata": {
        "id": "UH8MaRtK5LKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.8: 실습에 사용할 모델과 데이터셋 불러오기\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "klue_mrc_dataset = load_dataset(\"klue\", \"mrc\", split=\"train\")\n",
        "sentence_model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")"
      ],
      "metadata": {
        "id": "dtFVsE615c_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.9 코드를 실행해 데이터셋 중 1,000개만 선택하여 텍스트 임베딩으로 변환합니다(약 10분 소요)."
      ],
      "metadata": {
        "id": "-DIS4xnp5h8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.9: 실습 데이터에서 1,000개만 선택하고 문장 임베딩으로 변환\n",
        "klue_mrc_dataset = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)[\"train\"]\n",
        "embeddings = sentence_model.encode(klue_mrc_dataset[\"context\"])\n",
        "\n",
        "print(embeddings.shape)\n",
        "\n",
        "# 실행 결과\n",
        "# (1000, 768)"
      ],
      "metadata": {
        "id": "0bC3v4Eq5F8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.10 코드를 실행해 KNN 알고리즘을 활용하는 faiss의 IndexlFlatL2 클래스를 사용해 인덱스를 만듭니다.\n",
        "\n",
        "RDBMS에서의 데이터 입력과 유사한 작업입니다.\n",
        "\n",
        "인덱스 알고리즘 유형에는 검색 속도를 높일 수 있는 ANN도 있는데, 이에 대해서는 12장에서 학습할 수 있습니다."
      ],
      "metadata": {
        "id": "ShaZpLB452yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.10: KNN 검색 인덱스를 생성하고 문장 임베딩 저장\n",
        "import faiss\n",
        "\n",
        "index_flatl2 = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index_flatl2.add(embeddings)\n",
        "\n",
        "index_flatip = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index_flatip.add(embeddings)"
      ],
      "metadata": {
        "id": "akWCb4FW2tYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.11 코드를 실행해 인덱스에서 쿼리 임베딩 벡터와 유사한 문서를 검색해 봅니다.\n",
        "\n",
        "\n",
        "> <u>*index.search(query, k)*</u>\n",
        ">\n",
        "> 입력\n",
        "> - query: 인덱스에서 검색할 쿼리 임베딩 벡터\n",
        "> - k: 추출할 개수\n",
        ">\n",
        "> 출력\n",
        "> - [similarity, indices]\n",
        ">   - similarity: 유사도 측정 방식에 따른 계산 결과 값(Euclidean Distance, Inner Product 등)\n",
        ">   - indices: 검색한 벡터의 인덱스"
      ],
      "metadata": {
        "id": "EUbIPXQS5F1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.11: 의미 검색의 장점\n",
        "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
        "query_embedding = sentence_model.encode([query])\n",
        "\n",
        "print(\"[ flatl2 알고리즘 ]\")\n",
        "\n",
        "distances_flatl2, indices_flatl2 = index_flatip.search(query_embedding, 3)\n",
        "\n",
        "print(\"점수\\t\\t인덱스\\t내용\")\n",
        "\n",
        "for idx, content_idx in enumerate(indices_flatl2[0]):\n",
        "  print(f\"{distances_flatl2[0][idx]:.5f}\\t{indices_flatl2[0][idx]}\\t{klue_mrc_dataset['context'][content_idx][:100]}\")\n",
        "\n",
        "print(\"-\"*80)\n",
        "\n",
        "print(\"[ flatip 알고리즘 ]\")\n",
        "\n",
        "distances_flatip, indices_flatip = index_flatip.search(query_embedding, 3)\n",
        "\n",
        "print(\"점수\\t\\t인덱스\\t내용\")\n",
        "\n",
        "for idx, content_idx in enumerate(indices_flatip[0]):\n",
        "  print(f\"{distances_flatip[0][idx]:.5f}\\t{indices_flatip[0][idx]}\\t{klue_mrc_dataset['context'][content_idx][:100]}\")\n",
        "\n",
        "# 실행 결과\n",
        "# [ flatl2 알고리즘 ]\n",
        "# 점수\t\t인덱스\t내용\n",
        "# 133.35565\t0\t올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전\n",
        "# 62.83563\t396\t써머스플랫폼(대표 김기범)이 운영하는 '에누리 가격비교'가 최저가 스피드장보기로 알뜰하고 스마트한 추석차례상 쇼핑을 지원한다고 23일 밝혔다. 에누리 가격비교는 특히 올해 추석엔\n",
        "# 61.32185\t626\t새해 국내 이동통신 시장의 경쟁이 한층 뜨거워질 전망이다. 황창규 전 삼성전자 사장을 새 회장으로 맞은 KT가 이동통신 사업의 경쟁력 강화에 적극 나설 것으로 예상되기 때문이다.\n",
        "# --------------------------------------------------------------------------------\n",
        "# [ flatip 알고리즘 ]\n",
        "# 점수\t\t인덱스\t내용\n",
        "# 133.35565\t0\t올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전\n",
        "# 62.83563\t396\t써머스플랫폼(대표 김기범)이 운영하는 '에누리 가격비교'가 최저가 스피드장보기로 알뜰하고 스마트한 추석차례상 쇼핑을 지원한다고 23일 밝혔다. 에누리 가격비교는 특히 올해 추석엔\n",
        "# 61.32185\t626\t새해 국내 이동통신 시장의 경쟁이 한층 뜨거워질 전망이다. 황창규 전 삼성전자 사장을 새 회장으로 맞은 KT가 이동통신 사업의 경쟁력 강화에 적극 나설 것으로 예상되기 때문이다."
      ],
      "metadata": {
        "id": "v0CeuVDP8Jle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.12 코드를 실행해 의미 검색의 한계를 확인해 봅니다."
      ],
      "metadata": {
        "id": "yG_ZrBOp-E0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.12: 의미 검색의 한계\n",
        "query = \"로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\"\n",
        "query_embedding = sentence_model.encode([query])\n",
        "\n",
        "print(\"[ flatl2 알고리즘 ]\")\n",
        "\n",
        "distances_flatl2, indices_flatl2 = index_flatl2.search(query_embedding, 3)\n",
        "\n",
        "print(\"점수\\t\\t인덱스\\t내용\")\n",
        "\n",
        "for idx, content_idx in enumerate(indices_flatl2[0]):\n",
        "  print(f\"{distances_flatl2[0][idx]:.5f}\\t{indices_flatl2[0][idx]}\\t{klue_mrc_dataset['context'][content_idx][:100]}\")\n",
        "\n",
        "print(\"-\"*80)\n",
        "\n",
        "print(\"[ flatip 알고리즘 ]\")\n",
        "\n",
        "distances_flatip, indices_flatip = index_flatip.search(query_embedding, 3)\n",
        "\n",
        "print(\"점수\\t\\t인덱스\\t내용\")\n",
        "\n",
        "for idx, content_idx in enumerate(indices_flatip[0]):\n",
        "  print(f\"{distances_flatip[0][idx]:.5f}\\t{indices_flatip[0][idx]}\\t{klue_mrc_dataset['context'][content_idx][:100]}\")\n",
        "\n",
        "# 실행 결과\n",
        "# [ flatl2 알고리즘 ]\n",
        "# 점수\t\t인덱스\t내용\n",
        "# 240.37244\t78\t태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 하는 미 육군 주체의 연합군 남서 태평양 방면군은 1944년 후반 마침내 필리핀을 진공하기\n",
        "# 240.37244\t79\t태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 하는 미 육군 주체의 연합군 남서 태평양 방면군은 1944년 후반 마침내 필리핀을 진공하기\n",
        "# 242.09039\t3\t미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스터 대학교에서 핵물리학으로 박사 학위를 마쳤다. 제2차 세계대전중에 그는 매사추세츠 공과대\n",
        "# --------------------------------------------------------------------------------\n",
        "# [ flatip 알고리즘 ]\n",
        "# 점수\t\t인덱스\t내용\n",
        "# 100.07070\t293\t제2차 세계 대전이 일어난 동안 워너는 다시 전쟁의 노력을 후원하였다. 그는 미국 육군 항공대에 입대하여 중령의 계급에 도달하였다. 워너 브라더스 스튜디오는 또란 전쟁의 노력과 협\n",
        "# 100.07070\t292\t제2차 세계 대전이 일어난 동안 워너는 다시 전쟁의 노력을 후원하였다. 그는 미국 육군 항공대에 입대하여 중령의 계급에 도달하였다. 워너 브라더스 스튜디오는 또란 전쟁의 노력과 협\n",
        "# 96.97155\t3\t미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스터 대학교에서 핵물리학으로 박사 학위를 마쳤다. 제2차 세계대전중에 그는 매사추세츠 공과대"
      ],
      "metadata": {
        "id": "ta0-64v_ADYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "질문과 일치하는 답변은 3번째 기사이지만, 242.0904의 거리로 가장 마지막 결과로 조회되는 문제가 있습니다."
      ],
      "metadata": {
        "id": "VKPo_yvKATd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3.2 라마인덱스에서 Sentence-Transformers 모델 사용하기"
      ],
      "metadata": {
        "id": "5woSTKbPBC1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.13 코드를 실행해 Huggingface의 임베딩 모델을 가져와 인덱스를 생성합니다.\n",
        "\n",
        "> 책에서 사용한 ServiceContext는 deprecated 되었습니다(Settings로 대체).\n",
        ">\n",
        "> 기존에는 ServiceContext 객체의 from_defaults 메서드를 통해 llm, embedding_model 등을 지정했으나, 이제는 Settings 객체에서 곧바로 지정합니다.\n",
        ">\n",
        "> - 기존: ServiceContext.from_defaults(llm=\"AAA\", embed_model=\"BBB\")\n",
        ">\n",
        "> - 현재: Settings.llm_model = \"AAA\", Settings.embed_model = \"BBB\""
      ],
      "metadata": {
        "id": "6egFaNUXD7qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.13 라마인덱스에서 Sentence-Transformers 임베딩 모델 활용\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import Document\n",
        "from llama_index.core.settings import Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
        "\n",
        "text_list = klue_mrc_dataset[:100][\"context\"]\n",
        "documents = [Document(text=t) for t in text_list]\n",
        "\n",
        "index_llama = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "hNqflZyLAbtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.5 실습: 하이브리드 검색 구현하기"
      ],
      "metadata": {
        "id": "_OfIuzmwGFG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.5.1 BM25 구현하기"
      ],
      "metadata": {
        "id": "2Z3T5ntOGId-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.14: BM25 클래스 구현\n",
        "import math\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from transformers import PreTrainedTokenizer\n",
        "from collections import defaultdict\n",
        "\n",
        "class BM25:\n",
        "  def __init__(self, corpus:List[List[str]], tokenizer:PreTrainedTokenizer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.corpus = corpus\n",
        "    self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n",
        "    self.n_docs = len(self.tokenized_corpus)\n",
        "    self.avg_doc_lens = sum(len(lst) for lst in self.tokenized_corpus) / len(self.tokenized_corpus)\n",
        "    self.idf = self._calculate_idf()\n",
        "    self.term_freqs = self._calculate_term_freqs()\n",
        "\n",
        "  def _calculate_idf(self):\n",
        "    idf = defaultdict(float)\n",
        "\n",
        "    for doc in self.tokenized_corpus:\n",
        "      for token_id in set(doc):\n",
        "        idf[token_id] += 1\n",
        "\n",
        "    for token_id, doc_frequency in idf.items():\n",
        "      idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n",
        "\n",
        "    return idf\n",
        "\n",
        "  def _calculate_term_freqs(self):\n",
        "    term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n",
        "\n",
        "    for i, doc in enumerate(self.tokenized_corpus):\n",
        "      for token_id in doc:\n",
        "        term_freqs[i][token_id] += 1\n",
        "\n",
        "    return term_freqs\n",
        "\n",
        "  def get_scores(self, query:str, k1:float = 1.2, b:float=0.75):\n",
        "    query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n",
        "    scores = np.zeros(self.n_docs)\n",
        "\n",
        "    for q in query:\n",
        "      idf = self.idf[q]\n",
        "\n",
        "      for i, term_freq in enumerate(self.term_freqs):\n",
        "        q_frequency = term_freq[q]\n",
        "        doc_len = len(self.tokenized_corpus[i])\n",
        "        score_q = idf * (q_frequency * (k1 + 1)) / ((q_frequency) + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n",
        "        scores[i] += score_q\n",
        "\n",
        "    return scores\n",
        "\n",
        "  def get_top_k(self, query:str, k:int):\n",
        "    scores = self.get_scores(query)\n",
        "    top_k_indices = np.argsort(scores)[-k:][::-1]\n",
        "    top_k_scores = scores[top_k_indices]\n",
        "\n",
        "    return top_k_scores, top_k_indices\n"
      ],
      "metadata": {
        "id": "NKiXbuiNGHlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.15: BM25 점수 계산 확인해 보기\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
        "\n",
        "bm25 = BM25([\"안녕하세요\", \"반갑습니다\", \"안녕 서울\"], tokenizer)\n",
        "bm25.get_scores(\"안녕\")\n",
        "\n",
        "# 실행 결과\n",
        "# array([0.44713859, 0.        , 0.52354835])"
      ],
      "metadata": {
        "id": "dUkN1eUeJXsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 10.16 코드를 실행해 BM25 검색 결과의 한계를 확인합니다.\n",
        "\n",
        "'올여름 장마가…'로 시작하는 정답 기사가 가장 먼저 검색되어야 하지만, 일치하는 키워드가 적어 그렇지 않은 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "4xlWX4ABJ-LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.16: BM25 검색 결과의 한계\n",
        "bm25 = BM25(klue_mrc_dataset[\"context\"], tokenizer)\n",
        "\n",
        "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
        "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
        "\n",
        "for idx in bm25_search_ranking[:3]:\n",
        "  print(klue_mrc_dataset[\"context\"][idx][:100])\n",
        "\n",
        "# 실행 결과\n",
        "# 갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다”고 했다가 지금은 “판매시기 미정”. 삼성전자 갤럭시S5 판매 개시 시기를 놓고 SK텔레\n",
        "# 인구 비율당 노벨상을 세계에서 가장 많이 받은 나라, 과학 논문을 가장 많이 쓰고 의료 특허를 가장 많이 내는 나라, 세계적 금융위기 속에서 단 하나의 은행도 파산하지 않았고, 세\n",
        "# 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전"
      ],
      "metadata": {
        "id": "-6bGCzBvJcHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 10.17 코드를 실행해 BM25 검색 결과의 장점을 확인합니다.\n",
        "\n",
        "'매사추세츠 연구소' 표현이 많이 등장하는 기사가 연관성 1위로 반환된 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "p_Za-FTiKd8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.17: BM25 검색 결과의 장점\n",
        "query = klue_mrc_dataset[3]['question']  # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
        "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
        "\n",
        "for idx in bm25_search_ranking[:3]:\n",
        "  print(klue_mrc_dataset['context'][idx][:100])\n",
        "\n",
        "# 실행 결과\n",
        "# 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
        "# ;메카동(メカドン)\n",
        "# :성우 : 나라하시 미키(ならはしみき)\n",
        "# 길가에 버려져 있던 낡은 느티나\n",
        "# ;메카동(メカドン)\n",
        "# :성우 : 나라하시 미키(ならはしみき)\n",
        "# 길가에 버려져 있던 낡은 느티나"
      ],
      "metadata": {
        "id": "ZhOFf6hwJxFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 BM25를 코드로 구현하고 실제로 사용해 봄으로써 의미 검색과 서로 반대되는 장점과 단점을 가진 것을 확인할 수 있었습니다.\n",
        "\n",
        "다음으로는 하이브리드 검색을 구현하기 전, 두 검색 방식의 결과를 조합할 때 사용할 상호 순위 조합 방식을 코드로 구현해 보겠습니다."
      ],
      "metadata": {
        "id": "djU71stxLBTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.5.2 상호 순위 조합 구현하기"
      ],
      "metadata": {
        "id": "cZKBZsSrLNUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.18: 상호 순위 조합 함수 구현\n",
        "from collections import defaultdict\n",
        "\n",
        "def reciprocal_rank_fusion(rankings: List[List[int]], k=5):\n",
        "    rrf = defaultdict(float)\n",
        "\n",
        "    for ranking in rankings:\n",
        "        for i, doc_id in enumerate(ranking, 1):\n",
        "            rrf[doc_id] += 1.0 / (k + i)\n",
        "\n",
        "    return sorted(rrf.items(), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "Gx7HhvN1LMrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.19: 예시 데이터에 대한 상호 순위 조합 결과 확인하기\n",
        "rankings = [[1, 4, 3, 5, 6], [2, 1, 3, 6, 4]]\n",
        "reciprocal_rank_fusion(rankings)\n",
        "\n",
        "# 실행 결과\n",
        "# [(1, 0.30952380952380953),\n",
        "#  (3, 0.25),\n",
        "#  (4, 0.24285714285714285),\n",
        "#  (6, 0.2111111111111111),\n",
        "#  (2, 0.16666666666666666),\n",
        "#  (5, 0.1111111111111111)]"
      ],
      "metadata": {
        "id": "0NchJ8T-LWXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.5.3 하이브리드 검색 구현하기"
      ],
      "metadata": {
        "id": "4ZrTUH_vLnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.20: 하이브리드 검색 구현하기\n",
        "def dense_vector_search(query:str, k:int):\n",
        "  query_embedding = sentence_model.encode([query])\n",
        "  distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "  return distances[0], indices[0]\n",
        "\n",
        "def hybrid_search(query, k=20):\n",
        "  _, dense_search_ranking = dense_vector_search(query, 100)\n",
        "  _, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
        "\n",
        "  results = reciprocal_rank_fusion([dense_search_ranking, bm25_search_ranking], k=k)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "a5fzNwPgLp1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 10.21: 예시 데이터에 대한 하이브리드 검색 결과 확인\n",
        "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
        "print(\"검색 쿼리: \", query)\n",
        "\n",
        "results = hybrid_search(query)\n",
        "\n",
        "for idx, score in results[:3]:\n",
        "  print(f\"({score:.5f}) {klue_mrc_dataset['context'][idx][:50]}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "query = \"로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\"\n",
        "print(\"검색 쿼리: \", query)\n",
        "\n",
        "results = hybrid_search(query)\n",
        "\n",
        "for idx, score in results[:3]:\n",
        "  print(f\"({score:.5f}) {klue_mrc_dataset['context'][idx][:50]}\")\n",
        "\n",
        "# 실행 결과\n",
        "# 검색 쿼리:  이번 연도에는 언제 비가 많이 올까?\n",
        "# (0.09110) 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은\n",
        "# (0.05793) 갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
        "# (0.04545) 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그\n",
        "# --------------------------------------------------------------------------------\n",
        "# 검색 쿼리:  로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
        "# (0.09110) 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
        "# (0.06787) 1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n",
        "# (0.06734) 1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음"
      ],
      "metadata": {
        "id": "qKHN4PCuLuuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}